{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD_M73qh8FVV"
      },
      "source": [
        "# Introduction to Sentiment Analysis\n",
        "\n",
        "We will use the Python library '__TextBlob__' for this workshop. There are other alternatives but TextBlob provides all the basic functionality is relatively easy to learn.\n",
        "\n",
        "__TextBlob__ contains a pre-defined dictionary classifying negative and positive words. It works by analysing a given text and assigning individual scores to all the words it recognizes in a text. The final sentiment is calculated by  taking an average of all the individual sentiment scores. The range is from -1 (very negative) to +1 (very positive). \n",
        "\n",
        "## Install TextBlob and other libraries\n",
        "\n",
        "The first thing we need to do is install the necesssary Python libraries - this is straightforward using PIP (Python's package manager). Run this code block to install them. If you get a message, 'Requirement already satisfied', you can move on to the next section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WRy7q6M8FVY"
      },
      "outputs": [],
      "source": [
        "# Run this code block the first time you use this Notebook\n",
        "!pip install textblob\n",
        "!pip install nltk\n",
        "!pip install matplotlib\n",
        "!pip install pandas "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ESFTs3j8FVa"
      },
      "source": [
        "## Analyse some Text\n",
        "\n",
        "In this example we:\n",
        "\n",
        "- provide a small fragment of text\n",
        "- assign the text to a variable (a temporary container for holding the text)\n",
        "- pass that variable to TextBlob.\n",
        "\n",
        "TextBlob will then provide a result.\n",
        "\n",
        "Please note in the code below some text is prepended with #. This tells Python not to process this text so we can use it to provide comments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0ypoTl88FVa"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "#input_text = \"I think that big tech is doing a horrible thing for our country. And I believe it is going to be a catastrophic mistake for them.\" #(Donald Trump, Nov 13, 2020)\n",
        "\n",
        "input_text = \"This is a terrific book, the writing is superb, overall an excellent read\" # (Amazon review)\n",
        "\n",
        "blob = TextBlob(input_text) #pass the input text to Textblob\n",
        "\n",
        "polarity = (blob.sentiment.polarity) #get a polarity score\n",
        "\n",
        "print(polarity) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te5G3Zf78FVc"
      },
      "source": [
        "## Change the input text\n",
        "\n",
        "You should have got a result of -0.5 which is quite negative. To try this again with a different piece of text, comment out the second line of code containing the input_text (place a # at the beginning of the line) and remove the # at the beginning of the 3rd line of code.\n",
        "\n",
        "You should now get a score of 0.5 which is positive.\n",
        "\n",
        "## Subjectivity\n",
        "\n",
        "As well as providing a Sentiment score, TextBlob provides a Subjectivity score (between 0 and 1).  Subjectivity quantifies the amount of personal opinion and factual information contained in the text. The higher subjectivity means that the text contains personal opinion rather than factual information.\n",
        "\n",
        "We can improve the previous code by including a Subjectivity score. We will also do a small calculation to provide a textual indication of the overall Sentiment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIb-xn7P8FVd"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "input_text = \"the tiger is a different feline\" #(Donald Trump, Nov 13, 2020)\n",
        "\n",
        "#input_text = \"This is a terrific book, the writing is superb, overall an excellent read\" # (Amazon review)\n",
        "\n",
        "blob = TextBlob(input_text) #pass the input text to TextBlob\n",
        "\n",
        "polarity = blob.sentiment.polarity #get a polarity score\n",
        "\n",
        "subjectivity = blob.sentiment.subjectivity #get a subjectivity score\n",
        "\n",
        "if polarity > 0:\n",
        "  sentiment = \"Positive\"\n",
        "elif polarity < 0:\n",
        "   sentiment = \"Negative\"\n",
        "else:\n",
        "    sentiment = \"Neutral\"\n",
        "\n",
        "print('Polarity: ' + str(polarity))\n",
        "\n",
        "print('Subjectivity: ' + str(subjectivity))\n",
        "\n",
        "print('Sentiment: ' + sentiment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szuUQEpA8FVe"
      },
      "source": [
        "## Working with a text file\n",
        "\n",
        "It is useful to be able to analyse a file rather than a string of text.\n",
        "\n",
        "Our first dataset is here\n",
        "\n",
        "<a href=\"https://raw.githubusercontent.com/DCS-training/SentimentAnalysis/main/darwin-origin.txt\" download>https://raw.githubusercontent.com/DCS-training/SentimentAnalysis/main/darwin-origin.txt</a>\n",
        "\n",
        "We can import it directly from GitHub\n",
        "\n",
        "You can see how different books scores by changing which .txt file you are processing. go to <a href=\"https://github.com/DCS-training/SentimentAnalysis/blob/main/README.md\" download>https://github.com/DCS-training/SentimentAnalysis/blob/main/README.md </a>\n",
        "\n",
        "and see which other .txt files are available"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/DCS-training/SentimentAnalysis/main/darwin-origin.txt'\n",
        "input_text = pd.read_fwf(url)\n",
        "input_text =input_text.to_string()#Transform the dataframe into a string\n",
        "print(input_text)"
      ],
      "metadata": {
        "id": "PFdRnsa687Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhYrSqe68FVf"
      },
      "source": [
        "## Analyse the text file\n",
        "\n",
        "Now we can change our previous code to open a text file rather than reading a string of text.\n",
        "\n",
        "Notice in the following example I have used the Python 'round' function to convert the results to 2 decimal places.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg8pc6bf8FVg"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "blob = TextBlob(input_text) #pass the input text to TextBlob\n",
        "\n",
        "polarity = blob.sentiment.polarity #get a polarity score\n",
        "\n",
        "polarity = round(polarity, 2) # round to 2 decimal places\n",
        "\n",
        "subjectivity = blob.sentiment.subjectivity #get a subjectivity score\n",
        "\n",
        "subjectivity = round(subjectivity, 2) # round to 2 decimal places\n",
        "\n",
        "if polarity > 0:\n",
        "  sentiment = \"Positive\"\n",
        "elif polarity < 0:\n",
        "   sentiment = \"Negative\"\n",
        "else:\n",
        "    sentiment = \"Neutral\"\n",
        "\n",
        "print('Polarity: ' + str(polarity))\n",
        "\n",
        "print('Subjectivity: ' + str(subjectivity))\n",
        "\n",
        "print('Sentiment: ' + sentiment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZwgfPr78FVg"
      },
      "source": [
        "### Try diffent text files\n",
        "\n",
        "Experiment by analysing different text files. A selection can be found on the workshop home page (or use a file of you own choosing):\n",
        "\n",
        "[https://github.com/DCS-training/SentimentAnalysis/blob/main/README.md](https://github.com/DCS-training/SentimentAnalysis/blob/main/README.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIOks5Kz8FVg"
      },
      "source": [
        "## CSV Files\n",
        "\n",
        "You will often have data contained in a CSV file that you wish to analyse, this could be: the results of a survey, export from a database, collection of tweets.\n",
        "\n",
        "The following code example takes as its input a CSV file containing all Donald Trump's tweets in 2020, analyses each one for sentiment and creates a new CSV file containing the original text plus two new columns containing the Sentiment and Polarity.\n",
        "\n",
        "We can access the examples CSV files directly from GitHub \n",
        "\n",
        "<a href=\"https://raw.githubusercontent.com/DCS-training/SentimentAnalysis/main/trump-tweet-archive.csv\" download>https://raw.githubusercontent.com/DCS-training/SentimentAnalysis/main/trump-tweet-archive.csv</a>\n",
        "\n",
        "If you are using google colab, to see the newly created file you should go on the file explorer on the left handside and you will see the newly created.csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtbeyUHf8FVh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "import csv\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/DCS-training/SentimentAnalysis/main/trump-tweets-2020.csv'\n",
        "in_file = pd.read_csv(url)\n",
        "\n",
        "out_file = \"trump-tweets-2020-sentiment.csv\"\n",
        "\n",
        "# Create file to write our results to\n",
        "with open(out_file, \"w\", newline='', encoding='utf-8') as outfile:\n",
        "    # Add column titles to the first row\n",
        "    sntTweets = csv.writer(outfile)\n",
        "    sntTweets.writerow(['Tweet ID', 'Created', 'Tweet Text', 'sentiment','polarity' ])\n",
        "\n",
        "    # Open our Trump tweets csv file\n",
        "    for index, row in in_file.iterrows():\n",
        "        if('RT @' not in row['text']):  # Exclude retweets\n",
        "            tweet_id = row['id']\n",
        "            created_at = row['created_at']\n",
        "            tweet_text = row['text']\n",
        "\n",
        "            blob = TextBlob(tweet_text) #pass the tweet text to Textblob\n",
        "\n",
        "            polarity = (blob.sentiment.polarity) #get a polarity score\n",
        "\n",
        "            # Get the overall sentiment\n",
        "            if polarity > 0:\n",
        "              sentiment = \"positive\"\n",
        "            elif polarity < 0:\n",
        "               sentiment = \"negative\"\n",
        "            elif polarity == 0.0:\n",
        "                sentiment = \"neutral\"\n",
        "\n",
        "            #write data to CSV file\n",
        "            sntTweets.writerow(\n",
        "                [tweet_id, created_at, tweet_text, sentiment, polarity])\n",
        "\n",
        "    print (str(index+1) + ' tweets analysed for sentiment - results written to ' + out_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTKvkHx-8FVh"
      },
      "source": [
        "## Creating a Pie Chart of Sentiment of this CSV file\n",
        "\n",
        "Now we have scored each tweet for sentiment, using the Python Library 'MatPlotLib' it is easy to visualise the aggregate sentiment in this CSV file.\n",
        "\n",
        "The following code block, counts up the total number of each positive, negative and neutral tweets and outputs the result as a Pie Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HMvwJS48FVi"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "in_file = \"trump-tweets-2020-sentiment.csv\" #the file we just created\n",
        "\n",
        "# Open our Trump Tweets Sentiment csv file\n",
        "with open(in_file,  mode='r', newline='', encoding='utf-8') as infile:\n",
        "    reader = csv.reader(infile)\n",
        "    next(reader, None)  # ignore the existing headers\n",
        "\n",
        "    poscount = 0;  # establish a positive counter\n",
        "    negcount = 0;  # establish a negative counter\n",
        "    neucount = 0;  # establish a neutral counter\n",
        "\n",
        "    for row in reader:\n",
        "        if('RT @' not in row[2]):  # Exclude retweets\n",
        "           sent = row[3]\n",
        "\n",
        "           if sent == \"positive\":\n",
        "             poscount +=1\n",
        "           elif sent == \"negative\":\n",
        "              negcount += 1\n",
        "           else:\n",
        "               neucount +=1\n",
        "\n",
        "\n",
        "print('Positive: ' + str(poscount)) \n",
        "print('Negative: ' + str(negcount))\n",
        "print('Neutral: ' + str(neucount))\n",
        "\n",
        "\n",
        "sentiment = ['Positive','Negative','Neutral']\n",
        "scores = [poscount, negcount, neucount]\n",
        "\n",
        "colors = [\"#4CA948\", \"#DC1B1B\", \"#F77B02\", ]\n",
        "plt.pie(scores, labels=sentiment, colors=colors,\n",
        "autopct='%1.1f%%', shadow=True, startangle=140)\n",
        "plt.title(\"Sentiment Analysis of Trump Tweets\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--nL__DS8FVi"
      },
      "source": [
        "## Sentiment by Keyword\n",
        "\n",
        "Now that we have a CSV file scored for sentiment we can search the file for a particular keyword. The following code searches the Tweets in our CSV file for a keyword and for every hit, prints out the text with a polarity score at the end, and also provides an overall sentiment score. Try changing the originsl keyword to one of your own choosing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRZUo1J48FVj"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "import csv\n",
        "import sys\n",
        "\n",
        "keyword = \"dog\"\n",
        "inputfile = 'trump-tweets-2020-sentiment.csv'\n",
        "\n",
        "with open(inputfile, 'r', newline='', encoding='utf-8') as infile:\n",
        "    reader = csv.reader(infile, delimiter=',')\n",
        "    next(reader, None)  # skip the existing headers\n",
        "    cnt = 0\n",
        "    polarityscore = 0\n",
        "    for row in reader:\n",
        "\n",
        "        tweet_text = row[2]\n",
        "\n",
        "        if keyword.lower() in tweet_text.lower():\n",
        "\n",
        "            blob = TextBlob(tweet_text)\n",
        "\n",
        "            polarity = (blob.sentiment.polarity)\n",
        "\n",
        "            if polarity > 0:\n",
        "                sentiment = \"positive\"\n",
        "            elif polarity < 0:\n",
        "                sentiment = \"negative\"\n",
        "            elif polarity == 0.0:\n",
        "                sentiment = \"neutral\"\n",
        "            cnt += 1\n",
        "            polarityscore = polarityscore + polarity\n",
        "\n",
        "            print(str(cnt) + \". \" + tweet_text.replace(keyword, \"[\" + keyword + \"]\") + str(round(polarity, 2))+ '\\n')\n",
        "\n",
        "if cnt > 0:\n",
        "    avgpolarity = (polarityscore / cnt)\n",
        "\n",
        "    if avgpolarity > 0:\n",
        "        avgsentiment = \"positive\"\n",
        "    elif avgpolarity < 0:\n",
        "        avgsentiment = \"negative\"\n",
        "    elif avgpolarity == 0.0:\n",
        "        avgsentiment = \"neutral\"\n",
        "\n",
        "    print ('==================================================')\n",
        "    print ( str(cnt) + ' occurences of \"' + keyword.lstrip() + '\" found in text')\n",
        "    print ('Average Sentiment: ' + str(avgsentiment))\n",
        "    print ('Average Polarity: ' + str(round(avgpolarity,3)))\n",
        "    print ('==================================================')\n",
        "\n",
        "else:\n",
        "    print ('==================================================')\n",
        "    print ('No occurences of ' + keyword + ' found in text')\n",
        "    print ('==================================================')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXK4zUf78FVj"
      },
      "source": [
        "## Analysing a text file by keyword\n",
        "\n",
        "We can do a similar analysis by keyword of a text file. Here we will use the 'origin-intro.txt' we used earlier. This time the code will read in the sentence by sentence so we can analyse the keyword in context rather than just provide an overall result.\n",
        "\n",
        "Also, unlike the Trump Sentiment CSV we have not pre-analysed the text so we will do this 'on the fly' with TextBlob as we read each line. Try changing the keyword, but also experiment with different text files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwfgH3ky8FVk"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from textblob import TextBlob\n",
        "from nltk import sent_tokenize\n",
        "import pandas as pd\n",
        "\n",
        "searchterm = 'natural' # Choose a term to search for\n",
        "\n",
        "#Import file \n",
        "url = 'https://raw.githubusercontent.com/DCS-training/SentimentAnalysis/main/darwin-origin.txt'\n",
        "input_file = pd.read_fwf(url)\n",
        "input_text = input_file.to_string() # Transform the dataframe into a string\n",
        "\n",
        "# change searchterm and input text to lower case\n",
        "keyword = searchterm.lower()\n",
        "text_file = input_text.lower()\n",
        "\n",
        "polarityscore = 0\n",
        "cnt = 0\n",
        "\n",
        "input_text = sent_tokenize(text_file)\n",
        "\n",
        "for l in input_text:\n",
        "    if keyword.lower() in l.lower():\n",
        "        blob = TextBlob(l)\n",
        "\n",
        "        polarity = blob.sentiment.polarity\n",
        "\n",
        "        if polarity > 0:\n",
        "            sentiment = \"positive\"\n",
        "        elif polarity < 0:\n",
        "            sentiment = \"negative\"\n",
        "        else:\n",
        "            sentiment = \"neutral\"\n",
        "        \n",
        "        cnt += 1\n",
        "        polarityscore += polarity\n",
        "\n",
        "        print(str(cnt) + \". \" + l.lower().replace(keyword, \"[\"  + keyword + \"] \") + str(round(polarity, 2)) + '\\n' )\n",
        "\n",
        "if cnt > 0:\n",
        "    avgpolarity = polarityscore / cnt\n",
        "\n",
        "    if avgpolarity > 0:\n",
        "        avgsentiment = \"Positive\"\n",
        "    elif avgpolarity < 0:\n",
        "        avgsentiment = \"Negative\"\n",
        "    else:\n",
        "        avgsentiment = \"Neutral\"\n",
        "\n",
        "    print('==================================================')\n",
        "    print(str(cnt) + ' occurrences of \"' + keyword.lstrip() + '\" found in text')\n",
        "    print('Average Sentiment: ' + str(avgsentiment))\n",
        "    print('Average Polarity: ' + str(round(avgpolarity, 3)))\n",
        "    print('==================================================')\n",
        "\n",
        "else:\n",
        "    print('==================================================')\n",
        "    print('No occurrences of ' + keyword + ' found in text')\n",
        "    print('==================================================')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmMdw_F98FVk"
      },
      "source": [
        "## Analysing a text by sections\n",
        "\n",
        "Often you will want to analyse the different sections of a text to compare sentiment throughout. For example, analysing the sentiment of different chapters in a novel. To do this, it is necessary to identify in the text the various sections you wish to examine. Although it is often possible to use Python to do this, because the structure of documents can vary it is often easier to mark up the document manually. In the following example, I have taken a novel (Pride and Prejudice by Jane Austen) and inserted `<chapter></chapter>` tags to indicate where a chapter begins and ends.\n",
        "\n",
        "```\n",
        "\n",
        "<chapter>\n",
        "    CHAPTER 1\n",
        "    It is a truth universally acknowledged, that a single man in possession\n",
        "    of a good fortune, must be in want of a wife... \n",
        "</chapter>\n",
        "\n",
        "<chapter>\n",
        "    CHAPTER 2\n",
        "    Mr. Bennet was among the earliest of those who waited on Mr. Bingley...\n",
        "</chapter>\n",
        "\n",
        "```\n",
        "\n",
        "You can download it from here\n",
        "\n",
        "<a href=\"https://raw.githubusercontent.com/DCS-training/SentimentAnalysis/main/austen-pride-prejudice.txt\" download>https://raw.githubusercontent.com/DCS-training/SentimentAnalysis/main/austen-pride-prejudice.txt</a>\n",
        "\n",
        "### Analyse by Chapter\n",
        "\n",
        "Once you have uploaded the Pride and Prejudice text run the following code block.\n",
        "\n",
        "This will analyse each chapter for sentiment, print out a score for each chapter and an overall score. I will also create a csv file (named the same as the input file but with a .csv extension) that can be used to create avisualisation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPSWbA048FVl"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import re\n",
        "import urllib.request\n",
        "\n",
        "textURL = 'https://raw.githubusercontent.com/DCS-training/SentimentAnalysis/main/austen-pride.txt'\n",
        "csvName = 'austen-pride.csv'\n",
        "\n",
        "# Download text file from URL and read its contents\n",
        "response = urllib.request.urlopen(textURL)\n",
        "readFile = response.read().decode('utf-8')\n",
        "\n",
        "writeFile = csv.writer(open(csvName, \"w\"))\n",
        "\n",
        "textTitle = re.findall('<title>(.*?)</title>', readFile)\n",
        "textAuthor = re.findall('<author>(.*?)</author>', readFile, re.DOTALL)\n",
        "\n",
        "writeFile.writerow([\"Chapter\", \"Polarity\", \"Sentiment\"])\n",
        "\n",
        "chapters = re.findall('<chapter>(.*?)</chapter>', readFile, re.DOTALL)\n",
        "\n",
        "chapCounter = 0\n",
        "totalScore = 0\n",
        "for ch in chapters:\n",
        "\n",
        "    chapScore = 0\n",
        "    chapCounter += 1\n",
        "\n",
        "    blob = TextBlob(ch)\n",
        "    cnt = 0\n",
        "    for sentence in blob.sentences:\n",
        "        cnt += 1\n",
        "        chapScore = chapScore + (sentence.sentiment.polarity)\n",
        "        \n",
        "    chapScore = chapScore /cnt\n",
        "    \n",
        "    totalScore = totalScore + chapScore\n",
        "\n",
        "    print (str(chapCounter) + ' - ' + str(round(chapScore, 3)))\n",
        "\n",
        "    if chapScore > 0:\n",
        "        writeFile.writerow([str(chapCounter), round(chapScore, 3), 'Positive'])\n",
        "    elif chapScore < 0:\n",
        "        writeFile.writerow([str(chapCounter), round(chapScore, 3), 'Negative'])\n",
        "    else:\n",
        "        writeFile.writerow([str(chapCounter), round(chapScore, 3), 'Neutral'])\n",
        "\n",
        "\n",
        "avgSent = totalScore/chapCounter\n",
        "print ('***************************************')\n",
        "print (''.join(textTitle))\n",
        "print ('by')\n",
        "print (''.join(textAuthor))\n",
        "print ('Average chapter sentiment = ' + str(round(avgSent,3)))\n",
        "print ('csv created - ' +csvName)\n",
        "print ('***************************************')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_z_c-Gg8FVl"
      },
      "source": [
        "## Create a Barchart to illustrate results\n",
        "\n",
        "Using the CSV file created with last piece of code we can create a visualisation. \n",
        "\n",
        "Before running the next code block, from the top Noteable menu select: Cell > All Output > Clear\n",
        "\n",
        "Run the following code block to import the CSV and create a barchart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zYWW8JU8FVm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_file = 'austen-pride.csv'\n",
        "\n",
        "df_text = pd.read_csv(text_file)\n",
        "\n",
        "plt.figure(figsize=(9,6))\n",
        "\n",
        "plt.bar(x=df_text['Chapter'],\n",
        "\n",
        "height=df_text['Polarity'])\n",
        "\n",
        "plt.title('Pride and Prejudice - Sentiment by Chapter')\n",
        "\n",
        "plt.xlabel('Chapter')\n",
        "plt.ylabel('Polarity')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZaw0KyZ8FVm"
      },
      "source": [
        "## Further Exercises\n",
        "\n",
        "Experiment by analysing different text files. A selection can be found on this GitHub Repo\n",
        "You can either save them on your pc and import them or import them directly from the GitHub Repo. If you are using Noteable, once the file has been saved to your computer, go back to the Noteable home tab in the browser.\n",
        "\n",
        "* Select 'Upload' from the top right of the page. \n",
        "* Browse to the file.\n",
        "* Click 'Select'\n",
        "* Click on the blue 'Upload' button\n",
        "\n",
        "The file is now available to be used in Noteable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RX0O3m7b8FVm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}